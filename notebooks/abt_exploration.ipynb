{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from names_dataset import NameDataset\n",
    "from tqdm import tqdm\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "# Create a blank Tokenizer with just the English vocab\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Note\n",
    "Token labels are presented in BIO (Beginning, Inner, Outer) format. The PII type is prefixed with “B-” when it is the beginning of an entity. If the token is a continuation of an entity, it is prefixed with “I-”. Tokens that are not PII are labeled “O”.\n",
    "\n",
    "**Model idea** Lets instead of using the predefined token space, we define a new one without BIO definition, but where we concat tokens that are part of the same entity. We can then afterwards use SpaCy tokenizer to reverse the changes we made and get the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/train.json\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n",
       "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n",
       "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
       "      <td>[True, True, True, False, False, True, False, ...</td>\n",
       "      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>Assignment:  Visualization Reflection  Submitt...</td>\n",
       "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                          full_text  \\\n",
       "0         7  Design Thinking for innovation reflexion-Avril...   \n",
       "1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
       "2        16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
       "3        20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
       "4        56  Assignment:  Visualization Reflection  Submitt...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Design, Thinking, for, innovation, reflexion,...   \n",
       "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
       "3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
       "4  [Assignment, :,   , Visualization,  , Reflecti...   \n",
       "\n",
       "                                 trailing_whitespace  \\\n",
       "0  [True, True, True, True, False, False, True, F...   \n",
       "1  [True, False, False, True, True, False, False,...   \n",
       "2  [True, False, False, True, True, False, False,...   \n",
       "3  [True, True, True, False, False, True, False, ...   \n",
       "4  [False, False, False, False, False, False, Fal...   \n",
       "\n",
       "                                              labels  \n",
       "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n",
       "1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...  \n",
       "2  [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...  \n",
       "3  [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "O                   4989794\n",
       "B-NAME_STUDENT         1365\n",
       "I-NAME_STUDENT         1096\n",
       "B-URL_PERSONAL          110\n",
       "B-ID_NUM                 78\n",
       "B-EMAIL                  39\n",
       "I-STREET_ADDRESS         20\n",
       "I-PHONE_NUM              15\n",
       "B-USERNAME                6\n",
       "B-PHONE_NUM               6\n",
       "B-STREET_ADDRESS          2\n",
       "I-URL_PERSONAL            1\n",
       "I-ID_NUM                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df.labels.explode().reset_index(drop=True)\n",
    "labels_vc = labels.value_counts()\n",
    "labels_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new tokens by concatinating items in the tokens list until a 0 label is found\n",
    "# we do this for each row\n",
    "new_labels_dict = {\n",
    "    'O': 'O',\n",
    "    'B-URL_PERSONAL': 'URL_PERSONAL',\n",
    "    'I-URL_PERSONAL': 'URL_PERSONAL',\n",
    "    'B-EMAIL': 'EMAIL',\n",
    "    'I-EMAIL': 'EMAIL',\n",
    "    'B-ID_NUM': 'ID_NUM',\n",
    "    'I-ID_NUM': 'ID_NUM',\n",
    "    'I-STREET_ADDRESS': 'STREET_ADDRESS',\n",
    "    'B-STREET_ADDRESS': 'STREET_ADDRESS',\n",
    "    'I-PHONE_NUM': 'PHONE_NUM',\n",
    "    'B-PHONE_NUM': 'PHONE_NUM',\n",
    "    'B-USERNAME': 'USERNAME',\n",
    "    'I-USERNAME': 'USERNAME',\n",
    "    'B-PHONE_NUM': 'PHONE_NUM',\n",
    "    'I-PHONE_NUM': 'PHONE_NUM',\n",
    "    'I-URL_PERSONAL': 'URL_PERSONAL',\n",
    "    'B-URL_PERSONAL': 'URL_PERSONAL',\n",
    "    'B-NAME_STUDENT': 'NAME_STUDENT',\n",
    "    'I-NAME_STUDENT': 'NAME_STUDENT',\n",
    "}\n",
    "\n",
    "def create_new_tokens(row):\n",
    "    tokens = row[\"tokens\"]\n",
    "    labels = row[\"labels\"]\n",
    "    new_tokens = []\n",
    "    new_labels = []\n",
    "    building_token, building_token_label = \"\", None\n",
    "    for token, label in zip(tokens, labels):\n",
    "        # If the token is in the new_labels_dict, we start building the new token until we find a 0 label\n",
    "        if label in new_labels_dict and label != \"O\" and label != \"I-NAME_STUDENT\" and label != \"B-NAME_STUDENT\":\n",
    "            building_token += token\n",
    "            building_token_label = new_labels_dict[label]\n",
    "        # Else the new token is not PII class so we append the building token and the token to the new tokens list\n",
    "        else:\n",
    "            if building_token:\n",
    "                new_tokens.append(building_token)\n",
    "                new_labels.append(building_token_label)\n",
    "            \n",
    "            new_tokens.append(token)\n",
    "            new_labels.append(label)\n",
    "\n",
    "            building_token = \"\"\n",
    "\n",
    "    return new_tokens, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"new_tokens\", \"new_labels\"]] = df.apply(create_new_tokens, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "      <th>new_tokens</th>\n",
       "      <th>new_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n",
       "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n",
       "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
       "      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n",
       "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
       "      <td>[True, True, True, False, False, True, False, ...</td>\n",
       "      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n",
       "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
       "      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>Assignment:  Visualization Reflection  Submitt...</td>\n",
       "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n",
       "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                          full_text  \\\n",
       "0         7  Design Thinking for innovation reflexion-Avril...   \n",
       "1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
       "2        16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
       "3        20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
       "4        56  Assignment:  Visualization Reflection  Submitt...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Design, Thinking, for, innovation, reflexion,...   \n",
       "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
       "3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
       "4  [Assignment, :,   , Visualization,  , Reflecti...   \n",
       "\n",
       "                                 trailing_whitespace  \\\n",
       "0  [True, True, True, True, False, False, True, F...   \n",
       "1  [True, False, False, True, True, False, False,...   \n",
       "2  [True, False, False, True, True, False, False,...   \n",
       "3  [True, True, True, False, False, True, False, ...   \n",
       "4  [False, False, False, False, False, False, Fal...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...   \n",
       "1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...   \n",
       "2  [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...   \n",
       "3  [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...   \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...   \n",
       "\n",
       "                                          new_tokens  \\\n",
       "0  [Design, Thinking, for, innovation, reflexion,...   \n",
       "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
       "3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
       "4  [Assignment, :,   , Visualization,  , Reflecti...   \n",
       "\n",
       "                                          new_labels  \n",
       "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n",
       "1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...  \n",
       "2  [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...  \n",
       "3  [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "O                   4989794\n",
       "B-NAME_STUDENT         1365\n",
       "I-NAME_STUDENT         1096\n",
       "B-URL_PERSONAL          110\n",
       "B-ID_NUM                 78\n",
       "B-EMAIL                  39\n",
       "I-STREET_ADDRESS         20\n",
       "I-PHONE_NUM              15\n",
       "B-USERNAME                6\n",
       "B-PHONE_NUM               6\n",
       "B-STREET_ADDRESS          2\n",
       "I-URL_PERSONAL            1\n",
       "I-ID_NUM                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_exploded = df.tokens.explode().reset_index(drop=True)\n",
    "labels_exploded = df.labels.explode().reset_index(drop=True)\n",
    "labels_exploded.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Design\n",
       "1       Thinking\n",
       "2            for\n",
       "3     innovation\n",
       "4      reflexion\n",
       "5              -\n",
       "6          Avril\n",
       "7           2021\n",
       "8              -\n",
       "9       Nathalie\n",
       "10         Sylla\n",
       "11          \\n\\n\n",
       "12     Challenge\n",
       "13             &\n",
       "14     selection\n",
       "15          \\n\\n\n",
       "16           The\n",
       "17          tool\n",
       "18             I\n",
       "19           use\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_exploded[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and next time I want to concentrate on them , too \n",
      "\n",
      " Waseem Mabunda   591 Smith Centers Apt . 656 \n",
      " Joshuamouth , RI 95963 ( The Netherlands )\n",
      "--------------------------------------------------\n",
      "the business model , and got ourselves an   identity ( 1861 . Milano - 743 Erika Bypass Apt . 419 \n",
      " Andreahaven , IL 54207 ) looking forward to\n"
     ]
    }
   ],
   "source": [
    "ids = labels_exploded[labels_exploded == 'B-STREET_ADDRESS'].index\n",
    "print(\" \".join(tokens_exploded[ids[0]-15:ids[0]+15]))\n",
    "print(\"-\"*50)\n",
    "print(\" \".join(tokens_exploded[ids[1]-15:ids[1]+15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861200           Smith\n",
       "861201         Centers\n",
       "861202             Apt\n",
       "861203               .\n",
       "861204             656\n",
       "861205              \\n\n",
       "861206     Joshuamouth\n",
       "861207               ,\n",
       "861208              RI\n",
       "861209           95963\n",
       "1445331          Erika\n",
       "1445332         Bypass\n",
       "1445333            Apt\n",
       "1445334              .\n",
       "1445335            419\n",
       "1445336             \\n\n",
       "1445337    Andreahaven\n",
       "1445338              ,\n",
       "1445339             IL\n",
       "1445340          54207\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = labels_exploded[labels_exploded == 'I-STREET_ADDRESS'].index\n",
    "tokens_exploded[ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_labels\n",
       "O                 4989794\n",
       "B-NAME_STUDENT       1365\n",
       "I-NAME_STUDENT       1096\n",
       "URL_PERSONAL          110\n",
       "ID_NUM                 78\n",
       "EMAIL                  39\n",
       "USERNAME                6\n",
       "PHONE_NUM               6\n",
       "STREET_ADDRESS          2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens_exploded = df.new_tokens.explode().reset_index(drop=True)\n",
    "new_labels_exploded = df.new_labels.explode().reset_index(drop=True)\n",
    "new_labels_exploded.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861183     591SmithCentersApt.656\\nJoshuamouth,RI95963\n",
       "1445304     743ErikaBypassApt.419\\nAndreahaven,IL54207\n",
       "Name: new_tokens, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = new_labels_exploded[new_labels_exploded == 'STREET_ADDRESS'].index\n",
    "new_tokens_exploded[ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = new_labels_exploded[new_labels_exploded == \"ID_NUM\"].index\n",
    "b_ids = new_tokens_exploded[idx]\n",
    "b_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regex finding Ids in label specific:  73\n",
      "Regex finding Ids in all tokens:  248\n",
      "\n",
      "Accuracy Regex finding Ids in label specific:  0.9358974358974359\n",
      "Error of missclassification in whole 4.967455156699174e-05\n"
     ]
    }
   ],
   "source": [
    "reg = r'\\d{6,12}\\b|\\b[a-zA-Z]+\\d{2,}'\n",
    "specific_id = b_ids.str.contains(reg)\n",
    "ids_in_tokens = new_tokens_exploded.str.contains(reg)\n",
    "\n",
    "print('Regex finding Ids in label specific: ', specific_id.sum())\n",
    "print('Regex finding Ids in all tokens: ', ids_in_tokens.sum())\n",
    "print()\n",
    "print('Accuracy Regex finding Ids in label specific: ', specific_id.sum() / len(specific_id))\n",
    "# We calculate the percentage of ids we would have classified wrongly in the total amount of tokens\n",
    "print('Error of missclassification in whole', ids_in_tokens.sum() / len(ids_in_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = new_labels_exploded[new_labels_exploded == \"EMAIL\"].index\n",
    "b_email = new_tokens_exploded[idx]\n",
    "b_email.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regex finding Ids in label specific:  39\n",
      "Regex finding Ids in all tokens:  49\n",
      "\n",
      "Accuracy Regex finding Ids in label specific:  1.0\n",
      "Error of missclassification in whole 9.814729946704014e-06\n"
     ]
    }
   ],
   "source": [
    "reg = r'[\\w\\.-]+@[\\w\\.-]+'\n",
    "specific_id = b_email.str.match(reg)\n",
    "ids_in_tokens = new_tokens_exploded.str.match(reg)\n",
    "\n",
    "print('Regex finding Ids in label specific: ', specific_id.sum())\n",
    "print('Regex finding Ids in all tokens: ', ids_in_tokens.sum())\n",
    "print()\n",
    "print('Accuracy Regex finding Ids in label specific: ', specific_id.sum() / len(specific_id))\n",
    "# We calculate the percentage of ids we would have classified wrongly in the total amount of tokens\n",
    "print('Error of missclassification in whole', ids_in_tokens.sum() / len(ids_in_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL_PERSONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = new_labels_exploded[new_labels_exploded == \"URL_PERSONAL\"].index\n",
    "b_url = new_tokens_exploded[idx]\n",
    "b_url.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regex finding Ids in label specific:  109\n",
      "Regex finding Ids in all tokens:  327\n",
      "\n",
      "Accuracy Regex finding Ids in label specific:  0.990909090909091\n",
      "Error of missclassification in whole 6.54982998484125e-05\n"
     ]
    }
   ],
   "source": [
    "reg = r'https?://\\S+|www\\.\\S+'\n",
    "specific_id = b_url.str.match(reg)\n",
    "ids_in_tokens = new_tokens_exploded.str.match(reg)\n",
    "\n",
    "print('Regex finding Ids in label specific: ', specific_id.sum())\n",
    "print('Regex finding Ids in all tokens: ', ids_in_tokens.sum())\n",
    "print()\n",
    "print('Accuracy Regex finding Ids in label specific: ', specific_id.sum() / len(specific_id))\n",
    "# We calculate the percentage of ids we would have classified wrongly in the total amount of tokens\n",
    "print('Error of missclassification in whole', ids_in_tokens.sum() / len(ids_in_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PHONE_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = new_labels_exploded[new_labels_exploded == \"PHONE_NUM\"].index\n",
    "b_phone = new_tokens_exploded[idx]\n",
    "b_phone.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regex finding Ids in label specific:  6\n",
      "Regex finding Ids in all tokens:  327\n",
      "\n",
      "Accuracy Regex finding Ids in label specific:  1.0\n",
      "Error of missclassification in whole 6.54982998484125e-05\n"
     ]
    }
   ],
   "source": [
    "reg = r'\\(?(\\d{3})\\)?[-. ]?(\\d{3})[-. ]?(\\d{4})(x\\d{2,5})?'\n",
    "specific_id = b_phone.str.match(reg)\n",
    "\n",
    "print('Regex finding Ids in label specific: ', specific_id.sum())\n",
    "print('Regex finding Ids in all tokens: ', ids_in_tokens.sum())\n",
    "print()\n",
    "print('Accuracy Regex finding Ids in label specific: ', specific_id.sum() / len(specific_id))\n",
    "# We calculate the percentage of ids we would have classified wrongly in the total amount of tokens\n",
    "print('Error of missclassification in whole', ids_in_tokens.sum() / len(ids_in_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "We will attempt to create the simplest model possible. The model will evaluate each token and pass it through a couple functions to evaluate it. If one of the functions returns true, the token will be considered a keyword. The model will then return the keyword and the index of the token in the input string.\n",
    "\n",
    "### Model Functions\n",
    "- **email** This function will use regex to identify if the token is an email address.\n",
    "- **phone_num** This function will use regex to identify if the token is a phone number.\n",
    "- **address** This function will use regex to identify if the token is an address.\n",
    "- **username** This function will use a word embedding model to identify if the token is a common word and if not then we flag it as a username.\n",
    "- **personal_id** This function will use regex to identify if the token is a personal id.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = NameDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To do**\n",
    "Maybe we could make some more features for capitalised words etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.first_names.get(\"Design\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenizer(text):\n",
    "    # Remove excessive line breaks or spaces\n",
    "    text = re.sub('(\\r\\n){2,}', ' ', text)\n",
    "    \n",
    "    # Convert the text to lowercase and split into tokens\n",
    "    tokens = text.lower().split(\" \")\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "class PiiModel:\n",
    "    def __init__(self, text: str = None, names_dataset = None, tokens: list = None) -> None:\n",
    "        self.text = text\n",
    "        self.names = names_dataset\n",
    "        self.tokens = tokens\n",
    "        self.tokenizer = tokenizer\n",
    "        self.name_rank_threhsold = 120\n",
    "        self.country_threshold = 0.45\n",
    "        self.feature_df = pd.DataFrame()\n",
    "        pass\n",
    "    \n",
    "    def get_firstname(self, name: str) -> bool:\n",
    "        found_name = self.names.first_names.get(name.capitalize())\n",
    "        # we check if the max country is higher than a threshold then we say it is a valid name\n",
    "        if not found_name:\n",
    "            return {\"not_first_name\": 1}\n",
    "        return found_name\n",
    "    \n",
    "    def get_lastname(self, lastname: str) -> bool:\n",
    "        found_name = self.names.last_names.get(lastname.capitalize())\n",
    "        # we check if the max country is higher than a threshold then we say it is a valid name\n",
    "        if not found_name:\n",
    "            return {\"not_last_name\": 1}\n",
    "        return found_name\n",
    "    \n",
    "    def get_email_regex(self):\n",
    "        return r'[\\w\\.-]+@[\\w\\.-]+'\n",
    "    \n",
    "    def get_phone_number_regex(self):\n",
    "        return r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b'\n",
    "    \n",
    "    def get_address_regex(self):\n",
    "        return r'\\d{1,5}\\s\\w.\\s(\\b\\w*\\b\\s){1,2}\\w*\\.'\n",
    "    \n",
    "    def get_personal_id_regex(self):\n",
    "        return r'\\d{6,12}\\b|\\b[a-zA-Z]+\\d{2,}'\n",
    "    \n",
    "    def get_url_personal_regex(self):\n",
    "        return r'https?://[\\w\\.-]+'\n",
    "    \n",
    "    def numb_percent(self, text: str) -> float:\n",
    "        return sum(c.isdigit() for c in text) / len(text)\n",
    "    \n",
    "    def word_length(self, text: str) -> int:\n",
    "        return len(text)\n",
    "    \n",
    "    def is_punctuationmark(self, text: str) -> bool:\n",
    "        return text in [\".\", \",\", \"!\", \"?\", \";\", \":\"]\n",
    "    \n",
    "    def stop_words(self, text: str) -> bool:\n",
    "        return text in nlp.Defaults.stop_words\n",
    "    \n",
    "    def NER_ingest(self, text: str):\n",
    "        return nlp(text)\n",
    "    \n",
    "    def capitalize(self, text: str) -> bool:\n",
    "        return text[0].strip().isupper()\n",
    "\n",
    "    def build_features(self, text: str = \"\", tokens: list = None) -> list[tuple[int, str]]:\n",
    "        token_indices = self.tokens\n",
    "        if not self.tokens and text != \"\":\n",
    "            token_indices = self.tokenizer(text)\n",
    "            self.tokens = token_indices\n",
    "        if tokens:\n",
    "            token_indices = tokens\n",
    "        self.feature_df[\"token\"] = token_indices\n",
    "        # Computing Features\n",
    "        self.feature_df['first_name'] = self.feature_df['token'].apply(self.get_firstname)\n",
    "        json_normalised = pd.json_normalize(self.feature_df['first_name'], meta_prefix='first_name')\n",
    "        self.feature_df = pd.concat([self.feature_df, json_normalised], axis=1).drop(columns=['first_name']).fillna(0)\n",
    "\n",
    "        self.feature_df['last_name'] = self.feature_df['token'].apply(self.get_lastname)\n",
    "        json_normalised = pd.json_normalize(self.feature_df['last_name'], meta_prefix='last_name')\n",
    "        self.feature_df = pd.concat([self.feature_df, json_normalised], axis=1).drop(columns=['last_name']).fillna(0)\n",
    "\n",
    "        self.feature_df['email'] = self.feature_df['token'].apply(lambda x: bool(re.match(self.get_email_regex(), x)))\n",
    "        self.feature_df['phone_number'] = self.feature_df['token'].apply(lambda x: bool(re.match(self.get_phone_number_regex(), x)))\n",
    "        self.feature_df['address'] = self.feature_df['token'].apply(lambda x: bool(re.match(self.get_address_regex(), x)))\n",
    "        self.feature_df['personal_id'] = self.feature_df['token'].apply(lambda x: bool(re.match(self.get_personal_id_regex(), x)))\n",
    "        self.feature_df['url'] = self.feature_df['token'].apply(lambda x: bool(re.match(self.get_url_personal_regex(), x)))\n",
    "        self.feature_df['capitalized'] = self.feature_df['token'].apply(lambda x: self.capitalize(x))\n",
    "        self.feature_df['r_neighboured_capitalized'] = self.feature_df['capitalized'].shift(-1).fillna(False)\n",
    "        self.feature_df['l_neighboured_capitalized'] = self.feature_df['capitalized'].shift(1).fillna(False)\n",
    "        self.feature_df['numb_percent'] = self.feature_df['token'].apply(self.numb_percent)\n",
    "        self.feature_df['r_neighboured_numb_percent'] = self.feature_df['numb_percent'].shift(-1).fillna(False)\n",
    "        self.feature_df['l_neighboured_numb_percent'] = self.feature_df['numb_percent'].shift(1).fillna(False)\n",
    "        self.feature_df['word_length'] = self.feature_df['token'].apply(self.word_length)\n",
    "        self.feature_df['norm_index'] = self.feature_df.index / len(self.feature_df)\n",
    "        self.feature_df['is_punctuation'] = self.feature_df['token'].apply(self.is_punctuationmark)\n",
    "        self.feature_df['r_neighboured_punctuation'] = self.feature_df['is_punctuation'].shift(-1).fillna(False)\n",
    "        self.feature_df['l_neighboured_punctuation'] = self.feature_df['is_punctuation'].shift(1).fillna(False)\n",
    "        self.feature_df['stop_word'] = self.feature_df['token'].apply(self.stop_words)\n",
    "\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>not_first_name</th>\n",
       "      <th>country.AE</th>\n",
       "      <th>country.CO</th>\n",
       "      <th>country.EG</th>\n",
       "      <th>country.FR</th>\n",
       "      <th>country.GB</th>\n",
       "      <th>country.MA</th>\n",
       "      <th>country.MX</th>\n",
       "      <th>country.MY</th>\n",
       "      <th>...</th>\n",
       "      <th>numb_percent</th>\n",
       "      <th>r_neighboured_numb_percent</th>\n",
       "      <th>l_neighboured_numb_percent</th>\n",
       "      <th>word_length</th>\n",
       "      <th>norm_index</th>\n",
       "      <th>is_punctuation</th>\n",
       "      <th>r_neighboured_punctuation</th>\n",
       "      <th>l_neighboured_punctuation</th>\n",
       "      <th>stop_word</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Design</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thinking</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>innovation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reflexion</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 307 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        token  not_first_name  country.AE  country.CO  country.EG  country.FR  \\\n",
       "0      Design             1.0       0.000       0.000       0.000       0.000   \n",
       "1    Thinking             1.0       0.000       0.000       0.000       0.000   \n",
       "2         for             1.0       0.000       0.000       0.000       0.000   \n",
       "3  innovation             0.0       0.047       0.129       0.176       0.129   \n",
       "4   reflexion             1.0       0.000       0.000       0.000       0.000   \n",
       "\n",
       "   country.GB  country.MA  country.MX  country.MY  ...  numb_percent  \\\n",
       "0       0.000       0.000       0.000       0.000  ...           0.0   \n",
       "1       0.000       0.000       0.000       0.000  ...           0.0   \n",
       "2       0.000       0.000       0.000       0.000  ...           0.0   \n",
       "3       0.059       0.059       0.059       0.059  ...           0.0   \n",
       "4       0.000       0.000       0.000       0.000  ...           0.0   \n",
       "\n",
       "   r_neighboured_numb_percent  l_neighboured_numb_percent  word_length  \\\n",
       "0                         0.0                       False            6   \n",
       "1                         0.0                         0.0            8   \n",
       "2                         0.0                         0.0            3   \n",
       "3                         0.0                         0.0           10   \n",
       "4                         0.0                         0.0            9   \n",
       "\n",
       "   norm_index  is_punctuation  r_neighboured_punctuation  \\\n",
       "0    0.000000           False                      False   \n",
       "1    0.001328           False                      False   \n",
       "2    0.002656           False                      False   \n",
       "3    0.003984           False                      False   \n",
       "4    0.005312           False                      False   \n",
       "\n",
       "   l_neighboured_punctuation  stop_word  labels  \n",
       "0                      False      False       2  \n",
       "1                      False      False       2  \n",
       "2                      False       True       2  \n",
       "3                      False      False       2  \n",
       "4                      False      False       2  \n",
       "\n",
       "[5 rows x 307 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = df.iloc[0].new_tokens\n",
    "model = PiiModel(text=tokens, names_dataset=names)\n",
    "pii_indexes = model.build_features(tokens=tokens)\n",
    "model.feature_df['labels'] = df.iloc[0].new_labels\n",
    "model.feature_df['labels'] = model.feature_df['labels'].astype('category').cat.codes\n",
    "model.feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "2    747\n",
       "0      3\n",
       "1      3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data building\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = df.new_tokens.explode().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "We will use the XGBoost model to classify the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
