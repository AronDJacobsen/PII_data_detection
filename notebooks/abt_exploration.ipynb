{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from names_dataset import NameDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Note\n",
    "Token labels are presented in BIO (Beginning, Inner, Outer) format. The PII type is prefixed with “B-” when it is the beginning of an entity. If the token is a continuation of an entity, it is prefixed with “I-”. Tokens that are not PII are labeled “O”.\n",
    "\n",
    "**Model idea** Lets instead of using the predefined token space, we define a new one without BIO definition, but where we concat tokens that are part of the same entity. We can then afterwards use SpaCy tokenizer to reverse the changes we made and get the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/train.json\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n",
       "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n",
       "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
       "      <td>[True, True, True, False, False, True, False, ...</td>\n",
       "      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>Assignment:  Visualization Reflection  Submitt...</td>\n",
       "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                          full_text  \\\n",
       "0         7  Design Thinking for innovation reflexion-Avril...   \n",
       "1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
       "2        16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
       "3        20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
       "4        56  Assignment:  Visualization Reflection  Submitt...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Design, Thinking, for, innovation, reflexion,...   \n",
       "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
       "3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
       "4  [Assignment, :,   , Visualization,  , Reflecti...   \n",
       "\n",
       "                                 trailing_whitespace  \\\n",
       "0  [True, True, True, True, False, False, True, F...   \n",
       "1  [True, False, False, True, True, False, False,...   \n",
       "2  [True, False, False, True, True, False, False,...   \n",
       "3  [True, True, True, False, False, True, False, ...   \n",
       "4  [False, False, False, False, False, False, Fal...   \n",
       "\n",
       "                                              labels  \n",
       "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n",
       "1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...  \n",
       "2  [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...  \n",
       "3  [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "O                   4989794\n",
       "B-NAME_STUDENT         1365\n",
       "I-NAME_STUDENT         1096\n",
       "B-URL_PERSONAL          110\n",
       "B-ID_NUM                 78\n",
       "B-EMAIL                  39\n",
       "I-STREET_ADDRESS         20\n",
       "I-PHONE_NUM              15\n",
       "B-USERNAME                6\n",
       "B-PHONE_NUM               6\n",
       "B-STREET_ADDRESS          2\n",
       "I-URL_PERSONAL            1\n",
       "I-ID_NUM                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df.labels.explode().reset_index(drop=True)\n",
    "labels_vc = labels.value_counts()\n",
    "labels_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new tokens by concatinating items in the tokens list until a 0 label is found\n",
    "# we do this for each row\n",
    "new_labels_dict = {\n",
    "    'O': 'O',\n",
    "    'B-URL_PERSONAL': 'URL_PERSONAL',\n",
    "    'I-URL_PERSONAL': 'URL_PERSONAL',\n",
    "    'B-EMAIL': 'EMAIL',\n",
    "    'I-EMAIL': 'EMAIL',\n",
    "    'B-ID_NUM': 'ID_NUM',\n",
    "    'I-ID_NUM': 'ID_NUM',\n",
    "    'I-STREET_ADDRESS': 'STREET_ADDRESS',\n",
    "    'B-STREET_ADDRESS': 'STREET_ADDRESS',\n",
    "    'I-PHONE_NUM': 'PHONE_NUM',\n",
    "    'B-PHONE_NUM': 'PHONE_NUM',\n",
    "    'B-USERNAME': 'USERNAME',\n",
    "    'I-USERNAME': 'USERNAME',\n",
    "    'B-PHONE_NUM': 'PHONE_NUM',\n",
    "    'I-PHONE_NUM': 'PHONE_NUM',\n",
    "    'I-URL_PERSONAL': 'URL_PERSONAL',\n",
    "    'B-URL_PERSONAL': 'URL_PERSONAL',\n",
    "    'B-NAME_STUDENT': 'NAME_STUDENT',\n",
    "    'I-NAME_STUDENT': 'NAME_STUDENT',\n",
    "}\n",
    "\n",
    "def create_new_tokens(row):\n",
    "    tokens = row[\"tokens\"]\n",
    "    labels = row[\"labels\"]\n",
    "    new_tokens = []\n",
    "    new_labels = []\n",
    "    building_token, building_token_label = \"\", None\n",
    "    for token, label in zip(tokens, labels):\n",
    "        # If the token is in the new_labels_dict, we start building the new token until we find a 0 label\n",
    "        if label in new_labels_dict and label != \"O\" and label != \"I-NAME_STUDENT\" and label != \"B-NAME_STUDENT\":\n",
    "            building_token += token\n",
    "            building_token_label = new_labels_dict[label]\n",
    "        # Else the new token is not PII class so we append the building token and the token to the new tokens list\n",
    "        else:\n",
    "            if building_token:\n",
    "                new_tokens.append(building_token)\n",
    "                new_labels.append(building_token_label)\n",
    "            \n",
    "            new_tokens.append(token)\n",
    "            new_labels.append(label)\n",
    "\n",
    "            building_token = \"\"\n",
    "\n",
    "    return new_tokens, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"new_tokens\", \"new_labels\"]] = df.apply(create_new_tokens, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>full_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trailing_whitespace</th>\n",
       "      <th>labels</th>\n",
       "      <th>new_tokens</th>\n",
       "      <th>new_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[True, True, True, True, False, False, True, F...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
       "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n",
       "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
       "      <td>[True, False, False, True, True, False, False,...</td>\n",
       "      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n",
       "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
       "      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n",
       "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
       "      <td>[True, True, True, False, False, True, False, ...</td>\n",
       "      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n",
       "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
       "      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>Assignment:  Visualization Reflection  Submitt...</td>\n",
       "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
       "      <td>[False, False, False, False, False, False, Fal...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n",
       "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   document                                          full_text  \\\n",
       "0         7  Design Thinking for innovation reflexion-Avril...   \n",
       "1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
       "2        16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
       "3        20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
       "4        56  Assignment:  Visualization Reflection  Submitt...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Design, Thinking, for, innovation, reflexion,...   \n",
       "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
       "3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
       "4  [Assignment, :,   , Visualization,  , Reflecti...   \n",
       "\n",
       "                                 trailing_whitespace  \\\n",
       "0  [True, True, True, True, False, False, True, F...   \n",
       "1  [True, False, False, True, True, False, False,...   \n",
       "2  [True, False, False, True, True, False, False,...   \n",
       "3  [True, True, True, False, False, True, False, ...   \n",
       "4  [False, False, False, False, False, False, Fal...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...   \n",
       "1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...   \n",
       "2  [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...   \n",
       "3  [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...   \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...   \n",
       "\n",
       "                                          new_tokens  \\\n",
       "0  [Design, Thinking, for, innovation, reflexion,...   \n",
       "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
       "2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
       "3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
       "4  [Assignment, :,   , Visualization,  , Reflecti...   \n",
       "\n",
       "                                          new_labels  \n",
       "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n",
       "1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...  \n",
       "2  [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...  \n",
       "3  [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_labels\n",
       "O                 4989794\n",
       "B-NAME_STUDENT       1365\n",
       "I-NAME_STUDENT       1096\n",
       "URL_PERSONAL          110\n",
       "ID_NUM                 78\n",
       "EMAIL                  39\n",
       "USERNAME                6\n",
       "PHONE_NUM               6\n",
       "STREET_ADDRESS          2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens_exploded = df.new_tokens.explode().reset_index(drop=True)\n",
    "new_labels_exploded = df.new_labels.explode().reset_index(drop=True)\n",
    "new_labels_exploded.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24543      860632713425\n",
       "24556      530670102508\n",
       "24567      530670102508\n",
       "24573      875673967537\n",
       "24579      860632713425\n",
       "               ...     \n",
       "1842333       047378465\n",
       "2840555         IV-8322\n",
       "2841154         IV-8322\n",
       "3889578    Z.S.30407059\n",
       "4423790          V69230\n",
       "Name: new_tokens, Length: 78, dtype: object"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = new_labels_exploded[new_labels_exploded == 'ID_NUM'].index\n",
    "new_tokens_exploded[ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78,)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = new_labels_exploded[new_labels_exploded == \"ID_NUM\"].index\n",
    "b_ids = new_tokens_exploded[idx]\n",
    "b_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regex finding Ids in label specific:  73\n",
      "Regex finding Ids in all tokens:  248\n",
      "\n",
      "Accuracy Regex finding Ids in label specific:  0.9358974358974359\n",
      "Error of missclassification in whole 4.967455156699174e-05\n"
     ]
    }
   ],
   "source": [
    "reg = r'\\d{6,12}\\b|\\b[a-zA-Z]+\\d{2,}'\n",
    "specific_id = b_ids.str.contains(reg)\n",
    "ids_in_tokens = new_tokens_exploded.str.contains(reg)\n",
    "\n",
    "print('Regex finding Ids in label specific: ', specific_id.sum())\n",
    "print('Regex finding Ids in all tokens: ', ids_in_tokens.sum())\n",
    "print()\n",
    "print('Accuracy Regex finding Ids in label specific: ', specific_id.sum() / len(specific_id))\n",
    "# We calculate the percentage of ids we would have classified wrongly in the total amount of tokens\n",
    "print('Error of missclassification in whole', ids_in_tokens.sum() / len(ids_in_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EMAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39,)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = new_labels_exploded[new_labels_exploded == \"EMAIL\"].index\n",
    "b_email = new_tokens_exploded[idx]\n",
    "b_email.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regex finding Ids in label specific:  39\n",
      "Regex finding Ids in all tokens:  49\n",
      "\n",
      "Accuracy Regex finding Ids in label specific:  1.0\n",
      "Error of missclassification in whole 9.814729946704014e-06\n"
     ]
    }
   ],
   "source": [
    "reg = r'[\\w\\.-]+@[\\w\\.-]+'\n",
    "specific_id = b_email.str.match(reg)\n",
    "ids_in_tokens = new_tokens_exploded.str.match(reg)\n",
    "\n",
    "print('Regex finding Ids in label specific: ', specific_id.sum())\n",
    "print('Regex finding Ids in all tokens: ', ids_in_tokens.sum())\n",
    "print()\n",
    "print('Accuracy Regex finding Ids in label specific: ', specific_id.sum() / len(specific_id))\n",
    "# We calculate the percentage of ids we would have classified wrongly in the total amount of tokens\n",
    "print('Error of missclassification in whole', ids_in_tokens.sum() / len(ids_in_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL_PERSONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110,)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = new_labels_exploded[new_labels_exploded == \"URL_PERSONAL\"].index\n",
    "b_url = new_tokens_exploded[idx]\n",
    "b_url.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regex finding Ids in label specific:  109\n",
      "Regex finding Ids in all tokens:  327\n",
      "\n",
      "Accuracy Regex finding Ids in label specific:  0.990909090909091\n",
      "Error of missclassification in whole 6.54982998484125e-05\n"
     ]
    }
   ],
   "source": [
    "reg = r'https?://\\S+|www\\.\\S+'\n",
    "specific_id = b_url.str.match(reg)\n",
    "ids_in_tokens = new_tokens_exploded.str.match(reg)\n",
    "\n",
    "print('Regex finding Ids in label specific: ', specific_id.sum())\n",
    "print('Regex finding Ids in all tokens: ', ids_in_tokens.sum())\n",
    "print()\n",
    "print('Accuracy Regex finding Ids in label specific: ', specific_id.sum() / len(specific_id))\n",
    "# We calculate the percentage of ids we would have classified wrongly in the total amount of tokens\n",
    "print('Error of missclassification in whole', ids_in_tokens.sum() / len(ids_in_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PHONE_NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = new_labels_exploded[new_labels_exploded == \"PHONE_NUM\"].index\n",
    "b_phone = new_tokens_exploded[idx]\n",
    "b_phone.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regex finding Ids in label specific:  6\n",
      "Regex finding Ids in all tokens:  327\n",
      "\n",
      "Accuracy Regex finding Ids in label specific:  1.0\n",
      "Error of missclassification in whole 6.54982998484125e-05\n"
     ]
    }
   ],
   "source": [
    "reg = r'\\(?(\\d{3})\\)?[-. ]?(\\d{3})[-. ]?(\\d{4})(x\\d{2,5})?'\n",
    "specific_id = b_phone.str.match(reg)\n",
    "\n",
    "print('Regex finding Ids in label specific: ', specific_id.sum())\n",
    "print('Regex finding Ids in all tokens: ', ids_in_tokens.sum())\n",
    "print()\n",
    "print('Accuracy Regex finding Ids in label specific: ', specific_id.sum() / len(specific_id))\n",
    "# We calculate the percentage of ids we would have classified wrongly in the total amount of tokens\n",
    "print('Error of missclassification in whole', ids_in_tokens.sum() / len(ids_in_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "We will attempt to create the simplest model possible. The model will evaluate each token and pass it through a couple functions to evaluate it. If one of the functions returns true, the token will be considered a keyword. The model will then return the keyword and the index of the token in the input string.\n",
    "\n",
    "### Model Functions\n",
    "- **email** This function will use regex to identify if the token is an email address.\n",
    "- **phone_num** This function will use regex to identify if the token is a phone number.\n",
    "- **address** This function will use regex to identify if the token is an address.\n",
    "- **username** This function will use a word embedding model to identify if the token is a common word and if not then we flag it as a username.\n",
    "- **personal_id** This function will use regex to identify if the token is a personal id.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = NameDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(names.first_names.get(\"It\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To do**\n",
    "Maybe we could make some more features for capitalised words etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenizer(text):\n",
    "    # Remove excessive line breaks or spaces\n",
    "    text = re.sub('(\\r\\n){2,}', ' ', text)\n",
    "    \n",
    "    # Convert the text to lowercase and split into tokens\n",
    "    tokens = text.lower().split()\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "class PiiModel:\n",
    "    def __init__(self, text: str = None, names_dataset = None, tokens: list = None) -> None:\n",
    "        self.text = text\n",
    "        self.names = names_dataset\n",
    "        self.tokens = tokens\n",
    "        self.tokenizer = tokenizer\n",
    "        self.name_rank_threhsold = 120\n",
    "        self.country_threshold = 0.41\n",
    "        pass\n",
    "    \n",
    "    def get_firstname(self, name: str) -> bool:\n",
    "        found_name = self.names.first_names.get(name)\n",
    "        # we check if the max country is higher than a threshold then we say it is a valid name\n",
    "        if found_name != None and max(found_name[\"country\"].values()) > self.country_threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def get_lastname(self, lastname: str) -> bool:\n",
    "        found_name = self.names.last_names.get(lastname)\n",
    "        # we check if the max country is higher than a threshold then we say it is a valid name\n",
    "        if found_name != None and max(found_name[\"country\"].values()) > self.country_threshold:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def get_email_regex(self):\n",
    "        return r'[\\w\\.-]+@[\\w\\.-]+'\n",
    "    \n",
    "    def get_phone_number_regex(self):\n",
    "        return r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b'\n",
    "    \n",
    "    def get_address_regex(self):\n",
    "        return r'\\d{1,5}\\s\\w.\\s(\\b\\w*\\b\\s){1,2}\\w*\\.'\n",
    "    \n",
    "    def get_personal_id_regex(self):\n",
    "        # Any \n",
    "        return r'\\d{6,12}\\b|\\b[a-zA-Z]+\\d{2,}'\n",
    "    \n",
    "    def get_url_personal_regex(self):\n",
    "        return r'https?://[\\w\\.-]+'\n",
    "\n",
    "    def detect_pii(self, text: str = \"\", tokens: list = None) -> list[tuple[int, str]]:\n",
    "        token_indices = self.tokens\n",
    "        if not self.tokens and text != \"\":\n",
    "            token_indices = self.tokenizer(text)\n",
    "            self.tokens = token_indices\n",
    "        if tokens:\n",
    "            token_indices = tokens\n",
    "        pii_indexes = []\n",
    "        for i in range(len(token_indices)):\n",
    "            if re.search(self.get_email_regex(), token_indices[i]):\n",
    "                pii_indexes.append((token_indices[i], 'EMAIL'))\n",
    "            elif re.search(self.get_phone_number_regex(), token_indices[i]):\n",
    "                pii_indexes.append((token_indices[i], 'PHONE_NUM'))\n",
    "            elif re.search(self.get_address_regex(), token_indices[i]):\n",
    "                pii_indexes.append((token_indices[i], 'STREET_ADDRESS'))\n",
    "            elif re.search(self.get_personal_id_regex(), token_indices[i]):\n",
    "                pii_indexes.append((token_indices[i], 'ID_NUM'))\n",
    "            elif re.search(self.get_url_personal_regex(), token_indices[i]):\n",
    "                pii_indexes.append((token_indices[i], 'URL_PERSONAL'))\n",
    "            elif self.get_firstname(token_indices[i]):\n",
    "                pii_indexes.append((token_indices[i], 'B-NAME_STUDENT'))\n",
    "            elif self.get_lastname(token_indices[i]):\n",
    "                pii_indexes.append((token_indices[i], 'I-NAME_STUDENT'))\n",
    "            else:\n",
    "                pii_indexes.append((token_indices[i], 'O'))\n",
    "\n",
    "        return pii_indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = df.iloc[0].new_tokens\n",
    "model = PiiModel(tokens=tokens, names_dataset=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Design', 'O'), ('Thinking', 'O'), ('for', 'O'), ('innovation', 'O'), ('reflexion', 'O'), ('-', 'O'), ('Avril', 'I-NAME_STUDENT'), ('2021', 'O'), ('-', 'O'), ('Nathalie', 'B-NAME_STUDENT'), ('Sylla', 'B-NAME_STUDENT'), ('\\n\\n', 'O'), ('Challenge', 'O'), ('&', 'O'), ('selection', 'O'), ('\\n\\n', 'O'), ('The', 'O'), ('tool', 'O'), ('I', 'O'), ('use', 'O'), ('to', 'O'), ('help', 'O'), ('all', 'O'), ('stakeholders', 'O'), ('finding', 'O'), ('their', 'O'), ('way', 'O'), ('through', 'O'), ('the', 'O'), ('complexity', 'O'), ('of', 'O'), ('a', 'O'), ('project', 'O'), ('is', 'O'), ('the', 'O'), (' ', 'O'), ('mind', 'O'), ('map', 'O'), ('.', 'O'), ('\\n\\n', 'O'), ('What', 'O'), ('exactly', 'O'), ('is', 'O'), ('a', 'O'), ('mind', 'O'), ('map', 'O'), ('?', 'O'), ('According', 'B-NAME_STUDENT'), ('to', 'O'), ('the', 'O'), ('definition', 'O'), ('of', 'O'), ('Buzan', 'O'), ('T.', 'O'), ('and', 'O'), ('Buzan', 'O'), ('B.', 'O'), ('(', 'O'), ('1999', 'O'), (',', 'O'), ('Dessine', 'O'), ('-', 'O'), ('moi', 'O'), (' ', 'O'), (\"l'intelligence\", 'O'), ('.', 'O'), ('Paris', 'O'), (':', 'O'), ('Les', 'B-NAME_STUDENT'), ('Éditions', 'O'), (\"d'Organisation\", 'O'), ('.', 'O'), (')', 'O'), (',', 'O'), ('the', 'O'), ('mind', 'O'), ('map', 'O'), ('(', 'O'), ('or', 'O'), ('heuristic', 'O'), ('diagram', 'O'), (')', 'O'), ('is', 'O'), ('a', 'O'), ('graphic', 'O'), (' ', 'O'), ('representation', 'O'), ('technique', 'O'), ('that', 'O'), ('follows', 'O'), ('the', 'O'), ('natural', 'O'), ('functioning', 'O'), ('of', 'O'), ('the', 'O'), ('mind', 'O'), ('and', 'O'), ('allows', 'O'), ('the', 'O'), ('brain', 'O'), (\"'s\", 'O'), (' ', 'O'), ('potential', 'O'), ('to', 'O'), ('be', 'O'), ('released', 'O'), ('.', 'O'), ('Cf', 'O'), ('Annex1', 'O'), ('\\n\\n', 'O'), ('This', 'B-NAME_STUDENT'), ('tool', 'O'), ('has', 'O'), ('many', 'O'), ('advantages', 'O'), (':', 'O'), ('\\n\\n', 'O'), ('•', 'O'), (' ', 'O'), ('It', 'I-NAME_STUDENT'), ('is', 'O'), ('accessible', 'O'), ('to', 'O'), ('all', 'O'), ('and', 'O'), ('does', 'O'), ('not', 'O'), ('require', 'O'), ('significant', 'O'), ('material', 'O'), ('investment', 'O'), ('and', 'O'), ('can', 'O'), ('be', 'O'), ('done', 'O'), (' ', 'O'), ('quickly', 'O'), ('\\n\\n', 'O'), ('•', 'O'), (' ', 'O'), ('It', 'I-NAME_STUDENT'), ('is', 'O'), ('scalable', 'O'), ('\\n\\n', 'O'), ('•', 'O'), (' ', 'O'), ('It', 'I-NAME_STUDENT'), ('allows', 'O'), ('categorization', 'O'), ('and', 'O'), ('linking', 'O'), ('of', 'O'), ('information', 'O'), ('\\n\\n', 'O'), ('•', 'O'), (' ', 'O'), ('It', 'I-NAME_STUDENT'), ('can', 'O'), ('be', 'O'), ('applied', 'O'), ('to', 'O'), ('any', 'O'), ('type', 'O'), ('of', 'O'), ('situation', 'O'), (':', 'O'), ('notetaking', 'O'), (',', 'O'), ('problem', 'O'), ('solving', 'O'), (',', 'O'), ('analysis', 'O'), (',', 'O'), ('creation', 'O'), ('of', 'O'), (' ', 'O'), ('new', 'O'), ('ideas', 'O'), ('\\n\\n', 'O'), ('•', 'O'), (' ', 'O'), ('It', 'I-NAME_STUDENT'), ('is', 'O'), ('suitable', 'O'), ('for', 'O'), ('all', 'O'), ('people', 'O'), ('and', 'O'), ('is', 'O'), ('easy', 'O'), ('to', 'O'), ('learn', 'O'), ('\\n\\n', 'O'), ('•', 'O'), (' ', 'O'), ('It', 'I-NAME_STUDENT'), ('is', 'O'), ('fun', 'O'), ('and', 'O'), ('encourages', 'O'), ('exchanges', 'O'), ('\\n\\n', 'O'), ('•', 'O'), (' ', 'O'), ('It', 'I-NAME_STUDENT'), ('makes', 'O'), ('visible', 'O'), ('the', 'O'), ('dimension', 'O'), ('of', 'O'), ('projects', 'O'), (',', 'O'), ('opportunities', 'O'), (',', 'O'), ('interconnections', 'O'), ('\\n\\n', 'O'), ('•', 'O'), (' ', 'O'), ('It', 'I-NAME_STUDENT'), ('synthesizes', 'O'), ('\\n\\n', 'O'), ('•', 'O'), (' ', 'O'), ('It', 'I-NAME_STUDENT'), ('makes', 'O'), ('the', 'O'), ('project', 'O'), ('understandable', 'O'), ('\\n\\n', 'O'), ('•', 'O'), (' ', 'O'), ('It', 'I-NAME_STUDENT'), ('allows', 'O'), ('you', 'O'), ('to', 'O'), ('explore', 'O'), ('ideas', 'O'), ('\\n\\n', 'O'), ('The', 'O'), ('creation', 'O'), ('of', 'O'), ('a', 'O'), ('mind', 'O'), ('map', 'O'), ('starts', 'O'), ('with', 'O'), ('an', 'O'), ('idea', 'O'), ('/', 'O'), ('problem', 'O'), ('located', 'O'), ('at', 'O'), ('its', 'O'), ('center', 'O'), ('.', 'O'), ('This', 'B-NAME_STUDENT'), ('starting', 'O'), ('point', 'O'), (' ', 'O'), ('generates', 'O'), ('ideas', 'O'), ('/', 'O'), ('work', 'O'), ('areas', 'O'), (',', 'O'), ('incremented', 'O'), ('around', 'O'), ('this', 'O'), ('center', 'O'), ('in', 'O'), ('a', 'O'), ('radial', 'O'), ('structure', 'O'), (',', 'O'), ('which', 'O'), ('in', 'O'), ('turn', 'O'), ('is', 'O'), (' ', 'O'), ('completed', 'O'), ('with', 'O'), ('as', 'O'), ('many', 'O'), ('branches', 'O'), ('as', 'O'), ('new', 'O'), ('ideas', 'O'), ('.', 'O'), ('\\n\\n', 'O'), ('This', 'B-NAME_STUDENT'), ('tool', 'O'), ('enables', 'O'), ('creativity', 'O'), ('and', 'O'), ('logic', 'O'), ('to', 'O'), ('be', 'O'), ('mobilized', 'O'), (',', 'O'), ('it', 'O'), ('is', 'O'), ('a', 'O'), ('map', 'O'), ('of', 'O'), ('the', 'O'), ('thoughts', 'O'), ('.', 'O'), ('\\n\\n', 'O'), ('Creativity', 'O'), ('is', 'O'), ('enhanced', 'O'), ('because', 'O'), ('participants', 'O'), ('feel', 'O'), ('comfortable', 'O'), ('with', 'O'), ('the', 'O'), ('method', 'O'), ('.', 'O'), ('\\n\\n', 'O'), ('Application', 'O'), ('&', 'O'), ('Insight', 'O'), ('\\n\\n', 'O'), ('I', 'O'), ('start', 'O'), ('the', 'O'), ('process', 'O'), ('of', 'O'), ('the', 'O'), ('mind', 'O'), ('map', 'O'), ('creation', 'O'), ('with', 'O'), ('the', 'O'), ('stakeholders', 'O'), ('standing', 'O'), ('around', 'O'), ('a', 'O'), ('large', 'O'), ('board', 'O'), (' ', 'O'), ('(', 'O'), ('white', 'O'), ('or', 'O'), ('paper', 'O'), ('board', 'O'), (')', 'O'), ('.', 'O'), ('In', 'O'), ('the', 'O'), ('center', 'O'), ('of', 'O'), ('the', 'O'), ('board', 'O'), (',', 'O'), ('I', 'O'), ('write', 'O'), ('and', 'O'), ('highlight', 'O'), ('the', 'O'), ('topic', 'O'), ('to', 'O'), ('design', 'O'), ('.', 'O'), ('\\n\\n', 'O'), ('Through', 'O'), ('a', 'O'), ('series', 'O'), ('of', 'O'), ('questions', 'O'), (',', 'O'), ('I', 'O'), ('guide', 'O'), ('the', 'O'), ('stakeholders', 'O'), ('in', 'O'), ('modelling', 'O'), ('the', 'O'), ('mind', 'O'), ('map', 'O'), ('.', 'O'), ('I', 'O'), ('adapt', 'O'), ('the', 'O'), ('series', 'O'), (' ', 'O'), ('of', 'O'), ('questions', 'O'), ('according', 'O'), ('to', 'O'), ('the', 'O'), ('topic', 'O'), ('to', 'O'), ('be', 'O'), ('addressed', 'O'), ('.', 'O'), ('In', 'O'), ('the', 'O'), ('type', 'O'), ('of', 'O'), ('questions', 'O'), (',', 'O'), ('we', 'O'), ('can', 'O'), ('use', 'O'), (':', 'O'), ('who', 'O'), (',', 'O'), ('what', 'O'), (',', 'O'), (' ', 'O'), ('when', 'O'), (',', 'O'), ('where', 'O'), (',', 'O'), ('why', 'O'), (',', 'O'), ('how', 'O'), (',', 'O'), ('how', 'O'), ('much', 'O'), ('.', 'O'), ('\\n\\n', 'O'), ('The', 'O'), ('use', 'O'), ('of', 'O'), ('the', 'O'), ('“', 'O'), ('why', 'O'), ('”', 'O'), ('is', 'O'), ('very', 'O'), ('interesting', 'O'), ('to', 'O'), ('understand', 'O'), ('the', 'O'), ('origin', 'O'), ('.', 'O'), ('By', 'B-NAME_STUDENT'), ('this', 'O'), ('way', 'O'), (',', 'O'), ('the', 'O'), ('interviewed', 'O'), ('person', 'O'), (' ', 'O'), ('frees', 'O'), ('itself', 'O'), ('from', 'O'), ('paradigms', 'O'), ('and', 'O'), ('thus', 'O'), ('dares', 'O'), ('to', 'O'), ('propose', 'O'), ('new', 'O'), ('ideas', 'O'), ('/', 'O'), ('ways', 'O'), ('of', 'O'), ('functioning', 'O'), ('.', 'O'), ('I', 'O'), ('plan', 'O'), ('two', 'O'), (' ', 'O'), ('hours', 'O'), ('for', 'O'), ('a', 'O'), ('workshop', 'O'), ('.', 'O'), ('\\n\\n', 'O'), ('Design', 'O'), ('Thinking', 'O'), ('for', 'O'), ('innovation', 'O'), ('reflexion', 'O'), ('-', 'O'), ('Avril', 'I-NAME_STUDENT'), ('2021', 'O'), ('-', 'O'), ('Nathalie', 'B-NAME_STUDENT'), ('Sylla', 'B-NAME_STUDENT'), ('\\n\\n', 'O'), ('After', 'O'), ('modelling', 'O'), ('the', 'O'), ('mind', 'O'), ('map', 'O'), ('on', 'O'), ('paper', 'O'), (',', 'O'), ('I', 'O'), ('propose', 'O'), ('to', 'O'), ('the', 'O'), ('participants', 'O'), ('a', 'O'), ('digital', 'O'), ('visualization', 'O'), ('of', 'O'), ('their', 'O'), (' ', 'O'), ('work', 'O'), ('with', 'O'), ('the', 'O'), ('addition', 'O'), ('of', 'O'), ('color', 'O'), ('codes', 'O'), (',', 'O'), ('images', 'O'), ('and', 'O'), ('interconnections', 'O'), ('.', 'O'), ('This', 'B-NAME_STUDENT'), ('second', 'O'), ('workshop', 'O'), ('also', 'O'), ('lasts', 'O'), (' ', 'O'), ('two', 'O'), ('hours', 'O'), ('and', 'O'), ('allows', 'O'), ('the', 'O'), ('mind', 'O'), ('map', 'O'), ('to', 'O'), ('evolve', 'O'), ('.', 'O'), ('Once', 'O'), ('familiarized', 'O'), ('with', 'O'), ('it', 'O'), (',', 'O'), ('the', 'O'), ('stakeholders', 'O'), ('discover', 'O'), (' ', 'O'), ('the', 'O'), ('power', 'O'), ('of', 'O'), ('the', 'O'), ('tool', 'O'), ('.', 'O'), ('Then', 'B-NAME_STUDENT'), (',', 'O'), ('the', 'O'), ('second', 'O'), ('workshop', 'O'), ('brings', 'O'), ('out', 'O'), ('even', 'O'), ('more', 'O'), ('ideas', 'O'), ('and', 'O'), ('constructive', 'O'), (' ', 'O'), ('exchanges', 'O'), ('between', 'O'), ('the', 'O'), ('stakeholders', 'O'), ('.', 'O'), ('Around', 'O'), ('this', 'O'), ('new', 'O'), ('mind', 'O'), ('map', 'O'), (',', 'O'), ('they', 'O'), ('have', 'O'), ('learned', 'O'), ('to', 'O'), ('work', 'O'), (' ', 'O'), ('together', 'O'), ('and', 'O'), ('want', 'O'), ('to', 'O'), ('make', 'O'), ('visible', 'O'), ('the', 'O'), ('untold', 'O'), ('ideas', 'O'), ('.', 'O'), ('\\n\\n', 'O'), ('I', 'O'), ('now', 'O'), ('present', 'O'), ('all', 'O'), ('the', 'O'), ('projects', 'O'), ('I', 'O'), ('manage', 'O'), ('in', 'O'), ('this', 'O'), ('type', 'O'), ('of', 'O'), ('format', 'O'), ('in', 'O'), ('order', 'O'), ('to', 'O'), ('ease', 'O'), ('rapid', 'O'), ('understanding', 'O'), ('for', 'O'), (' ', 'O'), ('decision', 'O'), ('-', 'O'), ('makers', 'O'), ('.', 'O'), ('These', 'O'), ('presentations', 'O'), ('are', 'O'), ('the', 'O'), ('core', 'O'), ('of', 'O'), ('my', 'O'), ('business', 'O'), ('models', 'O'), ('.', 'O'), ('The', 'O'), ('decision', 'O'), ('-', 'O'), ('makers', 'O'), ('are', 'O'), (' ', 'O'), ('thus', 'O'), ('able', 'O'), ('to', 'O'), ('identify', 'O'), ('the', 'O'), ('opportunities', 'O'), ('of', 'O'), ('the', 'O'), ('projects', 'O'), ('and', 'O'), ('can', 'O'), ('take', 'O'), ('quick', 'O'), ('decisions', 'O'), ('to', 'O'), ('validate', 'O'), ('them', 'O'), ('.', 'O'), (' ', 'O'), ('They', 'O'), ('find', 'O'), ('answers', 'O'), ('to', 'O'), ('their', 'O'), ('questions', 'O'), ('thank', 'O'), ('to', 'O'), ('a', 'O'), ('schematic', 'O'), ('representation', 'O'), ('.', 'O'), ('\\n\\n', 'O'), ('Approach', 'O'), ('\\n\\n', 'O'), ('What', 'O'), ('I', 'O'), ('find', 'O'), ('amazing', 'O'), ('with', 'O'), ('the', 'O'), ('facilitation', 'O'), ('of', 'O'), ('this', 'O'), ('type', 'O'), ('of', 'O'), ('workshop', 'O'), ('is', 'O'), ('the', 'O'), ('participants', 'O'), ('commitment', 'O'), ('for', 'O'), (' ', 'O'), ('the', 'O'), ('project', 'O'), ('.', 'O'), ('This', 'B-NAME_STUDENT'), ('tool', 'O'), ('helps', 'O'), ('to', 'O'), ('give', 'O'), ('meaning', 'O'), ('.', 'O'), ('The', 'O'), ('participants', 'O'), ('appropriate', 'O'), ('the', 'O'), ('story', 'O'), ('and', 'O'), ('want', 'O'), ('to', 'O'), ('keep', 'O'), (' ', 'O'), ('writing', 'O'), ('it', 'O'), ('.', 'O'), ('Then', 'B-NAME_STUDENT'), (',', 'O'), ('they', 'O'), ('easily', 'O'), ('become', 'O'), ('actors', 'O'), ('or', 'O'), ('sponsors', 'O'), ('of', 'O'), ('the', 'O'), ('project', 'O'), ('.', 'O'), ('A', 'O'), ('trust', 'O'), ('relationship', 'O'), ('is', 'O'), ('built', 'O'), (',', 'O'), (' ', 'O'), ('thus', 'O'), ('facilitating', 'O'), ('the', 'O'), ('implementation', 'O'), ('of', 'O'), ('related', 'O'), ('actions', 'O'), ('.', 'O'), ('\\n\\n', 'O'), ('Design', 'O'), ('Thinking', 'O'), ('for', 'O'), ('innovation', 'O'), ('reflexion', 'O'), ('-', 'O'), ('Avril', 'I-NAME_STUDENT'), ('2021', 'O'), ('-', 'O'), ('Nathalie', 'B-NAME_STUDENT'), ('Sylla', 'B-NAME_STUDENT'), ('\\n\\n', 'O'), ('Annex', 'O'), ('1', 'O'), (':', 'O'), ('Mind', 'O'), ('Map', 'O'), ('Shared', 'O'), ('facilities', 'O'), ('project', 'O'), ('\\n\\n', 'O')]\n"
     ]
    }
   ],
   "source": [
    "pii_indexes = model.detect_pii(tokens=tokens)\n",
    "print(pii_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "We will now attempt to evaluate the model against the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6807it [00:15, 448.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 4924168\n",
      "False Positives: 68311\n",
      "Precision: 0.9863172183598569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "fp = 0\n",
    "failed = []\n",
    "correct = []\n",
    "\n",
    "for row in tqdm(df.iterrows()):\n",
    "    # Make predictions using the model\n",
    "    # Replace `model.predict()` with the actual prediction code\n",
    "    predictions = model.detect_pii(tokens=row[1][\"new_tokens\"])\n",
    "    \n",
    "    # Compare the predictions with the ground truth labels\n",
    "    for pred, label in zip(predictions, row[1][\"new_labels\"]):\n",
    "        if pred[0] == \"O\":\n",
    "            continue\n",
    "        if pred[1] == label:\n",
    "            tp += 1\n",
    "            correct.append((pred[0], pred[1], label))\n",
    "        else:\n",
    "            fp += 1\n",
    "            failed.append((pred[0], pred[1], label))\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"True Positives:\", tp)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"Precision:\", tp / (tp + fp))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
