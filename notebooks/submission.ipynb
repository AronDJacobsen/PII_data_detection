{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/augusttollerup/Documents/KSEM2/ABA/PII_data_detection/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "from names_dataset import NameDataset\n",
    "from tqdm import tqdm\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "# Create a blank Tokenizer with just the English vocab\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/wikineural-multilingual-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Babelscape/wikineural-multilingual-ner\")\n",
    "ner_model = pipeline(\"ner\", model=model, tokenizer=tokenizer, grouped_entities=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Note\n",
    "Token labels are presented in BIO (Beginning, Inner, Outer) format. The PII type is prefixed with “B-” when it is the beginning of an entity. If the token is a continuation of an entity, it is prefixed with “I-”. Tokens that are not PII are labeled “O”.\n",
    "\n",
    "**Model idea** Lets instead of using the predefined token space, we define a new one without BIO definition, but where we concat tokens that are part of the same entity. We can then afterwards use SpaCy tokenizer to reverse the changes we made and get the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/train.json\"\n",
    "file_path_test = \"../data/test.json\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "with open(file_path_test, \"r\") as file:\n",
    "    data_test = json.load(file)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df_test = pd.DataFrame(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "We will attempt to create the simplest model possible. The model will evaluate each token and pass it through a couple functions to evaluate it. If one of the functions returns true, the token will be considered a keyword. The model will then return the keyword and the index of the token in the input string.\n",
    "\n",
    "### Model Functions\n",
    "- **email** This function will use regex to identify if the token is an email address.\n",
    "- **phone_num** This function will use regex to identify if the token is a phone number.\n",
    "- **address** This function will use regex to identify if the token is an address.\n",
    "- **username** This function will use a word embedding model to identify if the token is a common word and if not then we flag it as a username.\n",
    "- **personal_id** This function will use regex to identify if the token is a personal id.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = NameDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To do**\n",
    "Maybe we could make some more features for capitalised words etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenizer(text):\n",
    "    # Remove excessive line breaks or spaces\n",
    "    text = re.sub('(\\r\\n){2,}', ' ', text)\n",
    "    \n",
    "    # Convert the text to lowercase and split into tokens\n",
    "    tokens = text.lower().split(\" \")\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "class PiiModel:\n",
    "    def __init__(self, text: str = None, \n",
    "                 names_dataset = None, tokens: list = None, \n",
    "                 significant_tokens: dict = None, \n",
    "                 dataframe: pd.DataFrame = None, full_text: str = None):\n",
    "        self.text = text\n",
    "        self.names = names_dataset\n",
    "        self.tokens = tokens\n",
    "        self.tokenizer = tokenizer\n",
    "        self.name_rank_threhsold = 1500\n",
    "        self.country_threshold = 0.01\n",
    "        self.significant_tokens = significant_tokens\n",
    "        self.feature_df = pd.DataFrame()\n",
    "        self.input_df = dataframe\n",
    "        self.full_text = full_text\n",
    "        pass\n",
    "    \n",
    "    def get_firstname(self, name: str) -> bool:\n",
    "        found_name = self.names.first_names.get(name.capitalize())\n",
    "\n",
    "        if not found_name:\n",
    "            return False\n",
    "        country = found_name[\"country\"]\n",
    "        # If any of the countries has a higher percentage than the threshold and the rank is lower than the threshold\n",
    "        if any(value > self.country_threshold for value in country.values()) and any(rank < self.name_rank_threhsold for rank in found_name[\"rank\"].values()):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    \n",
    "    def get_lastname(self, lastname: str) -> bool:\n",
    "        found_name = self.names.last_names.get(lastname.capitalize())\n",
    "        # we check if the max country is higher than a threshold then we say it is a valid name\n",
    "        if not found_name:\n",
    "            return False\n",
    "        country = found_name[\"country\"]\n",
    "        if any(value > self.country_threshold for value in country.values()) and any(rank < self.name_rank_threhsold for rank in found_name[\"rank\"].values()):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def get_email_regex(self):\n",
    "        return r'[\\w\\.-]+@[\\w\\.-]+'\n",
    "    \n",
    "    def get_phone_number_regex(self):\n",
    "        return r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b'\n",
    "    \n",
    "    def get_address_regex(self):\n",
    "        return r'\\d{1,5}\\s\\w.\\s(\\b\\w*\\b\\s){1,2}\\w*\\.'\n",
    "    \n",
    "    def get_personal_id_regex(self):\n",
    "        return r'\\d{6,12}\\b|\\b[a-zA-Z]+\\d{2,}'\n",
    "    \n",
    "    def get_url_personal_regex(self):\n",
    "        return r'https?://[\\w\\.-]+'\n",
    "    \n",
    "    def numb_percent(self, text: str) -> float:\n",
    "        return sum(c.isdigit() for c in text) / len(text)\n",
    "    \n",
    "    def word_length(self, text: str) -> int:\n",
    "        return len(text)\n",
    "    \n",
    "    def is_punctuationmark(self, text: str) -> bool:\n",
    "        return text in [\".\", \",\", \"!\", \"?\", \";\", \":\"]\n",
    "    \n",
    "    def stop_words(self, text: str) -> bool:\n",
    "        return text in nlp.Defaults.stop_words\n",
    "    \n",
    "    def capitalize(self, text: str) -> bool:\n",
    "        return text[0].strip().isupper()\n",
    "    \n",
    "    def NER_ingest(self, text: str):\n",
    "        return ner_model(text)\n",
    "\n",
    "    def contextual_ner_person(self, text: str) -> bool:\n",
    "        return text in list(self.NER_persons)\n",
    "    \n",
    "    def contextual_ner_location(self, text: str) -> bool:\n",
    "        return text in (self.NER_locations)\n",
    "    \n",
    "    def check_preceding_contextual_tokens(self, index, label):\n",
    "        # Extract relevant tokens directly, avoiding repeated DataFrame row access\n",
    "        start_index = max(0, index-2)\n",
    "        tokens_to_check = self.feature_df['token'][start_index:index]\n",
    "        \n",
    "        # Get the set of significant tokens for the label, defaulting to an empty set if not found\n",
    "        significant_tokens_set = self.significant_tokens.get(label, set())\n",
    "        \n",
    "        # Check if any of the tokens to check are in the significant tokens set\n",
    "        return any(token in significant_tokens_set for token in tokens_to_check)\n",
    "\n",
    "    \n",
    "    def build_df(self, text: str = \"\", tokens: list = None, labels: list = None) -> pd.DataFrame:\n",
    "        token_indices = self.tokens\n",
    "        if not self.tokens and text != \"\":\n",
    "            token_indices = self.tokenizer(text)\n",
    "            self.tokens = token_indices\n",
    "        if tokens:\n",
    "            token_indices = tokens\n",
    "        elif self.input_df is not None:\n",
    "            token_indices = self.input_df[\"tokens\"]\n",
    "        self.feature_df[\"token\"] = token_indices\n",
    "\n",
    "        self.feature_df['labels'] = labels\n",
    "        return None\n",
    "\n",
    "    def build_features(self) -> list[tuple[int, str]]:\n",
    "        # Computing Features\n",
    "        self.feature_df['first_name'] = self.feature_df['token'].apply(self.get_firstname)\n",
    "        self.feature_df['last_name'] = self.feature_df['token'].apply(self.get_lastname)\n",
    "        self.feature_df['email'] = self.feature_df['token'].apply(lambda x: bool(re.match(self.get_email_regex(), x)))\n",
    "        self.feature_df['phone_number'] = self.feature_df['token'].apply(lambda x: bool(re.match(self.get_phone_number_regex(), x)))\n",
    "        self.feature_df['address'] = self.feature_df['token'].apply(lambda x: bool(re.match(self.get_address_regex(), x)))\n",
    "        self.feature_df['personal_id'] = self.feature_df['token'].apply(lambda x: bool(re.match(self.get_personal_id_regex(), x)))\n",
    "        self.feature_df['url'] = self.feature_df['token'].apply(lambda x: bool(re.match(self.get_url_personal_regex(), x)))\n",
    "        self.feature_df['capitalized'] = self.feature_df['token'].apply(lambda x: self.capitalize(x))\n",
    "        self.feature_df['numb_percent'] = self.feature_df['token'].apply(self.numb_percent)\n",
    "        self.feature_df['word_length'] = self.feature_df['token'].apply(self.word_length)\n",
    "        self.feature_df['norm_index'] = self.feature_df.index / len(self.feature_df)\n",
    "        self.feature_df['is_punctuation'] = self.feature_df['token'].apply(self.is_punctuationmark)\n",
    "        self.feature_df['stop_word'] = self.feature_df['token'].apply(self.stop_words)\n",
    "\n",
    "        ingested = self.NER_ingest(self.full_text)\n",
    "\n",
    "        self.NER_persons = pd.Series([entity['word'] for entity in ingested if entity['entity_group'] == 'PER']).explode().reset_index(drop=True)\n",
    "        self.NER_locations = pd.Series([entity['word'] for entity in ingested if entity['entity_group'] == 'LOC']).explode().reset_index(drop=True)\n",
    "\n",
    "        self.feature_df['contextual_ner_person'] = self.feature_df['token'].apply(self.contextual_ner_person)\n",
    "        self.feature_df['contextual_ner_location'] = self.feature_df['token'].apply(self.contextual_ner_location)\n",
    "\n",
    "        # Window\n",
    "        for i in range(1, 6):\n",
    "            self.feature_df[f'r_neighboured_email_{i}'] = self.feature_df['email'].shift(-i).fillna(False)\n",
    "            self.feature_df[f'l_neighboured_email_{i}'] = self.feature_df['email'].shift(i).fillna(False)\n",
    "            self.feature_df[f'r_neighboured_phone_number_{i}'] = self.feature_df['phone_number'].shift(-i).fillna(False)\n",
    "            self.feature_df[f'l_neighboured_phone_number_{i}'] = self.feature_df['phone_number'].shift(i).fillna(False)\n",
    "            self.feature_df[f'r_neighboured_address_{i}'] = self.feature_df['address'].shift(-i).fillna(False)\n",
    "            self.feature_df[f'l_neighboured_address_{i}'] = self.feature_df['address'].shift(i).fillna(False)\n",
    "            self.feature_df[f'r_neighboured_personal_id_{i}'] = self.feature_df['personal_id'].shift(-i).fillna(False)\n",
    "            self.feature_df[f'l_neighboured_personal_id_{i}'] = self.feature_df['personal_id'].shift(i).fillna(False)\n",
    "            self.feature_df[f'r_neighboured_url_{i}'] = self.feature_df['url'].shift(-i).fillna(False)\n",
    "            self.feature_df[f'l_neighboured_url_{i}'] = self.feature_df['url'].shift(i).fillna(False)\n",
    "            self.feature_df[f'r_neighboured_capitalized_{i}'] = self.feature_df['capitalized'].shift(-i).fillna(False)\n",
    "            self.feature_df[f'l_neighboured_capitalized_{i}'] = self.feature_df['capitalized'].shift(i).fillna(False)\n",
    "            self.feature_df[f'r_neighboured_numb_percent_{i}'] = self.feature_df['numb_percent'].shift(-i).fillna(False)\n",
    "            self.feature_df[f'l_neighboured_numb_percent_{i}'] = self.feature_df['numb_percent'].shift(i).fillna(False)\n",
    "            self.feature_df[f'r_neighboured_punctuation_{i}'] = self.feature_df['is_punctuation'].shift(-i).fillna(False)\n",
    "            self.feature_df[f'l_neighboured_punctuation_{i}'] = self.feature_df['is_punctuation'].shift(i).fillna(False)\n",
    "            self.feature_df[f'r_neighboured_stop_word_{i}'] = self.feature_df['stop_word'].shift(-i).fillna(False)\n",
    "            self.feature_df[f'l_neighboured_stop_word_{i}'] = self.feature_df['stop_word'].shift(i).fillna(False)\n",
    "            self.feature_df[f'r_neighboured_word_length_{i}'] = self.feature_df['word_length'].shift(-i).fillna(False)\n",
    "            self.feature_df[f'l_neighboured_word_length_{i}'] = self.feature_df['word_length'].shift(i).fillna(False)\n",
    "            self.feature_df[f'r_neighboured_first_name_{i}'] = self.feature_df['first_name'].shift(-i).fillna(False)\n",
    "            self.feature_df[f'l_neighboured_first_name_{i}'] = self.feature_df['first_name'].shift(i).fillna(False)\n",
    "            self.feature_df[f'r_neighboured_last_name_{i}'] = self.feature_df['last_name'].shift(-i).fillna(False)\n",
    "            self.feature_df[f'l_neighboured_last_name_{i}'] = self.feature_df['last_name'].shift(i).fillna(False)\n",
    "            self.feature_df[f'r_neighboured_contextual_ner_person_{i}'] = self.feature_df['contextual_ner_person'].shift(-i).fillna(False)\n",
    "            self.feature_df[f'l_neighboured_contextual_ner_person_{i}'] = self.feature_df['contextual_ner_person'].shift(i).fillna(False)\n",
    "            self.feature_df[f'r_neighboured_contextual_ner_location_{i}'] = self.feature_df['contextual_ner_location'].shift(-i).fillna(False)\n",
    "            self.feature_df[f'l_neighboured_contextual_ner_location_{i}'] = self.feature_df['contextual_ner_location'].shift(i).fillna(False)\n",
    "\n",
    "\n",
    "        if self.input_df is not None:\n",
    "            self.feature_df[\"text_index\"] = self.input_df.text_index\n",
    "        # Add a new feature for each label based on contextual tokens\n",
    "        for label in self.significant_tokens.keys():\n",
    "            feature_name = f'{label.lower()}_contextual_presence'\n",
    "            self.feature_df[feature_name] = [self.check_preceding_contextual_tokens(i, label) for i in range(len(self.feature_df))]\n",
    "\n",
    "\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preceeding Words analysis on Xtrain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1155.49it/s]\n"
     ]
    }
   ],
   "source": [
    "dfs_analysis = []\n",
    "\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    tokens, labels = df.tokens.iloc[i], df.labels.iloc[i]\n",
    "    model = PiiModel(text=tokens, names_dataset=names)\n",
    "    model.build_df(tokens=tokens, labels=labels)\n",
    "    \n",
    "    # Reset index and drop the old index to ensure unique indices\n",
    "    model.feature_df.reset_index(drop=True, inplace=True)\n",
    "    # drop duplicate columns\n",
    "    model.feature_df = model.feature_df.loc[:,~model.feature_df.columns.duplicated()]\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    dfs_analysis.append(model.feature_df)\n",
    "\n",
    "X_analysis = pd.concat(dfs_analysis, axis=0)\n",
    "X_analysis.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_analysis_df = X_analysis[['token', 'labels']].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'B-NAME_STUDENT', 'I-NAME_STUDENT', 'B-URL_PERSONAL',\n",
       "       'B-EMAIL', 'B-ID_NUM'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_analysis_df.labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preceding_tokens(row_index, N, dataframe):\n",
    "    # Calculate the start index to avoid negative indexing\n",
    "    start_index = max(0, row_index - N)\n",
    "    # Extract preceding N tokens, if the row_index is not at the very beginning\n",
    "    if start_index < row_index:\n",
    "        return dataframe.iloc[start_index:row_index]['token'].tolist()\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "N = 2  # Example: Look 5 tokens back\n",
    "labels_of_interest = ['B-NAME_STUDENT', 'I-NAME_STUDENT', 'B-ID_NUM',\n",
    "       'B-URL_PERSONAL', 'B-EMAIL', 'B-USERNAME', 'I-URL_PERSONAL',\n",
    "       'I-ID_NUM', 'B-STREET_ADDRESS', 'I-STREET_ADDRESS']\n",
    "\n",
    "# Initialize a dictionary to hold token frequencies for each label\n",
    "token_frequencies_by_label = {label: {} for label in labels_of_interest}\n",
    "\n",
    "for label in labels_of_interest:\n",
    "    # Filter rows for the specific label\n",
    "    label_indices = _analysis_df[_analysis_df['labels'] == label].index\n",
    "    \n",
    "    # Collect preceding tokens for each occurrence of the label\n",
    "    for index in label_indices:\n",
    "        preceding_tokens = get_preceding_tokens(index, N, _analysis_df)\n",
    "        for token in preceding_tokens:\n",
    "            if token in token_frequencies_by_label[label]:\n",
    "                token_frequencies_by_label[label][token] += 1\n",
    "            else:\n",
    "                token_frequencies_by_label[label][token] = 1\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# This dictionary will count the occurrences of each token across labels\n",
    "token_occurrences_across_labels = defaultdict(int)\n",
    "\n",
    "# Count occurrences of each token across different labels\n",
    "for label, frequencies in token_frequencies_by_label.items():\n",
    "    for token in frequencies.keys():\n",
    "        token_occurrences_across_labels[token] += 1\n",
    "\n",
    "# Identify tokens that appear in more than one label's frequency dictionary\n",
    "common_tokens = {token for token, count in token_occurrences_across_labels.items() if count > 1}\n",
    "\n",
    "\n",
    "# Remove common tokens from each label's frequency dictionary\n",
    "filtered_token_frequencies_by_label = {\n",
    "    label: {token: frequency for token, frequency in frequencies.items() if token not in common_tokens}\n",
    "    for label, frequencies in token_frequencies_by_label.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:37<00:00,  2.70it/s]\n"
     ]
    }
   ],
   "source": [
    "dfs_train = []\n",
    "\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    tokens, labels = df.tokens.iloc[i], df.labels.iloc[i]\n",
    "    model = PiiModel(text=tokens, names_dataset=names, significant_tokens=token_frequencies_by_label, full_text=df.full_text.iloc[i])\n",
    "    model.build_df(tokens=tokens, labels=labels)\n",
    "    model.build_features()\n",
    "    \n",
    "    # Reset index and drop the old index to ensure unique indices\n",
    "    model.feature_df.reset_index(drop=True, inplace=True)\n",
    "    # drop duplicate columns\n",
    "    model.feature_df = model.feature_df.loc[:,~model.feature_df.columns.duplicated()]\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    dfs_train.append(model.feature_df)\n",
    "\n",
    "X_train = pd.concat(dfs_train, axis=0)\n",
    "X_train.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:03<00:00,  2.65it/s]\n"
     ]
    }
   ],
   "source": [
    "dfs_test = []\n",
    "\n",
    "for i in tqdm(range(df_test.shape[0])):\n",
    "    tokens = df_test.tokens.iloc[i]\n",
    "    model = PiiModel(text=tokens, names_dataset=names, significant_tokens=token_frequencies_by_label, full_text=df_test.full_text.iloc[i])\n",
    "    model.build_df(tokens=tokens)\n",
    "    model.build_features()\n",
    "    \n",
    "    # Reset index and drop the old index to ensure unique indices\n",
    "    model.feature_df.reset_index(drop=True, inplace=True)\n",
    "    # drop duplicate columns\n",
    "    model.feature_df = model.feature_df.loc[:,~model.feature_df.columns.duplicated()]\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    dfs_test.append(model.feature_df)\n",
    "\n",
    "X_test = pd.concat(dfs_test, axis=0)\n",
    "X_test.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling\n",
    "We will use the XGBoost model to classify the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "y_train = X_train['labels']\n",
    "y_test = X_test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_jobs=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_jobs=-1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_jobs=-1)\n",
    "model.fit(X_train.drop(columns=[\"token\", \"labels\"]), y_train.explode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test.drop(columns=[\"token\", \"labels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_ids = df_test.explode(\"tokens\").document\n",
    "token_ids = df_test.tokens.apply(lambda x: list(range(len(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"document\": document_ids.reset_index(drop=True),\n",
    "    \"token\": token_ids.explode().reset_index(drop=True),\n",
    "    \"label\": pd.Series(predictions).explode().reset_index(drop=True),\n",
    "    })\n",
    "submission = submission[submission.label != \"O\"].reset_index(drop=True)\n",
    "submission[\"row_id\"] = submission.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
